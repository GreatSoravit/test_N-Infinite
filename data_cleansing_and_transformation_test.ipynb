{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Transformation Test\n",
    "\n",
    "Use file `./ref/sample_user_data.csv` for input\n",
    "\n",
    "Use `pandas` lib or other lib if you want\n",
    "\n",
    "Write your code and display the result in specific cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29 entries, 0 to 28\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   user_id    29 non-null     int64  \n",
      " 1   name       29 non-null     object \n",
      " 2   age        26 non-null     float64\n",
      " 3   join_date  27 non-null     object \n",
      " 4   salary     29 non-null     object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 1.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>join_date</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Alice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>52000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bob</td>\n",
       "      <td>34.0</td>\n",
       "      <td>02/03/2023</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bob</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Emma</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Grek</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23000.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>allen</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2023-09-23</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Allen</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2023-09-23</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>chris</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>35,000.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Bob</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Bobb</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>Bob</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Bab</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>Bob</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Bob</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>69000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Toby</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Eggy</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13</td>\n",
       "      <td>Bab</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>Emma</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>22,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17</td>\n",
       "      <td>Eggy</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>Bob</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>19</td>\n",
       "      <td>BOB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20</td>\n",
       "      <td>muller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21</td>\n",
       "      <td>MIke</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2022-03-15</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>22</td>\n",
       "      <td>Toby</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>23</td>\n",
       "      <td>Vin</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2223-03-02</td>\n",
       "      <td>148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>24</td>\n",
       "      <td>Gin</td>\n",
       "      <td>940.0</td>\n",
       "      <td>2003-03-02</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>25</td>\n",
       "      <td>james</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2043-03-02</td>\n",
       "      <td>169000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id    name    age   join_date     salary\n",
       "0         1    John   28.0  2023-02-01      50000\n",
       "1         2   Alice    NaN  2023-02-02      52000\n",
       "2         3     Bob   34.0  02/03/2023      49000\n",
       "3         3     Bob   34.0  2023-03-02      49000\n",
       "4         4    Emma   45.0         NaN      47000\n",
       "5         5    Grek   32.0         NaN   23000.32\n",
       "6         6   allen   26.0  2023-09-23      30000\n",
       "7         7   Allen   26.0  2023-09-23      30000\n",
       "8         8   chris   28.0  2020-11-13  35,000.25\n",
       "9         9     Bob   33.0  2023-04-02      49000\n",
       "10       10    Bobb   34.0  2023-03-01      49000\n",
       "11        9     Bob   33.0  2023-04-02      49000\n",
       "12       12   Bobby   34.0  2023-03-01      49000\n",
       "13       13     Bab   39.0  2023-02-02      49000\n",
       "14        3     Bob   34.0  2023-03-02      49000\n",
       "15       15     Bob   39.0  2024-03-02      69000\n",
       "16       16    Toby   34.0  2023-03-02      49000\n",
       "17       17    Eggy   36.0  2023-12-16      58000\n",
       "18       13     Bab   39.0  2023-02-02      49000\n",
       "19       18    Emma   22.0  2023-03-02     22,000\n",
       "20       17    Eggy   36.0  2023-12-16      58000\n",
       "21        9     Bob   33.0  2023-04-02      49000\n",
       "22       19     BOB    NaN  2023-04-02     100000\n",
       "23       20  muller    NaN  2023-04-15     100000\n",
       "24       21    MIke   54.0  2022-03-15     120000\n",
       "25       22    Toby  134.0  2023-03-02     149000\n",
       "26       23     Vin   40.0  2223-03-02     148000\n",
       "27       24     Gin  940.0  2003-03-02     149000\n",
       "28       25   james   60.0  2043-03-02     169000"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv file\n",
    "\n",
    "df = pd.read_csv(\"./ref/sample_user_data.csv\")\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "There're data quality issues, such as outliers, null values, and incorrect data types.  \n",
    "\n",
    "1. Validate fields.\n",
    "2. Clean data by handling missing values.\n",
    "3. Deduplicate record (if any).\n",
    "4. Standardize any inconsistent data (e.g., date formats).\n",
    "\n",
    "\n",
    "There're several conditions,\n",
    "1.  Replace NaN in age value with \"-\"\n",
    "2.  Format join_date to date type.\n",
    "    -   YYYY-MM-DD i.e. 2024-11-03\n",
    "    -   DD/MM/YYYY i.e. 03/12/2023\n",
    "    -   remove NaN value\n",
    "3. Name should be captitalized.\n",
    "\n",
    "\n",
    "\n",
    "#### Example Data Quality Checks:\n",
    "- Identify outliers in numerical fields (e.g., ages > 100).\n",
    "- Ensure no future dates in a date column.\n",
    "- user_id not be empty\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_23460\\395399287.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleansing_df[\"join_date\"].loc[wrong_date_index] = fix_date_list\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>join_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>is_valid_age</th>\n",
       "      <th>is_valid_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>50000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>52000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bob</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>49000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Allen</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2023-09-23</td>\n",
       "      <td>30000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Allen</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2023-09-23</td>\n",
       "      <td>30000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>Chris</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>35000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>Bob</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>49000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>Bobb</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>49000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>49000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>Bab</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>49000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>Bob</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>69000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>Toby</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>49000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>Eggy</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>58000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18</td>\n",
       "      <td>Emma</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>22000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>100000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>Muller</td>\n",
       "      <td>-</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>100000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21</td>\n",
       "      <td>Mike</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2022-03-15</td>\n",
       "      <td>120000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22</td>\n",
       "      <td>Toby</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>149000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24</td>\n",
       "      <td>Gin</td>\n",
       "      <td>940.0</td>\n",
       "      <td>2003-03-02</td>\n",
       "      <td>149000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id    name    age  join_date  salary  is_valid_age  is_valid_date\n",
       "0         1    John   28.0 2023-02-01   50000         False           True\n",
       "1         2   Alice      - 2023-02-02   52000         False           True\n",
       "2         3     Bob   34.0 2023-03-02   49000         False          False\n",
       "3         6   Allen   26.0 2023-09-23   30000         False           True\n",
       "4         7   Allen   26.0 2023-09-23   30000         False           True\n",
       "5         8   Chris   28.0 2020-11-13   35000         False           True\n",
       "6         9     Bob   33.0 2023-04-02   49000         False           True\n",
       "7        10    Bobb   34.0 2023-03-01   49000         False           True\n",
       "8        12   Bobby   34.0 2023-03-01   49000         False           True\n",
       "9        13     Bab   39.0 2023-02-02   49000         False           True\n",
       "10       15     Bob   39.0 2024-03-02   69000         False           True\n",
       "11       16    Toby   34.0 2023-03-02   49000         False           True\n",
       "12       17    Eggy   36.0 2023-12-16   58000         False           True\n",
       "13       18    Emma   22.0 2023-03-02   22000         False           True\n",
       "14       19     Bob      - 2023-04-02  100000         False           True\n",
       "15       20  Muller      - 2023-04-15  100000         False           True\n",
       "16       21    Mike   54.0 2022-03-15  120000         False           True\n",
       "17       22    Toby  134.0 2023-03-02  149000          True           True\n",
       "18       24     Gin  940.0 2003-03-02  149000          True           True"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write you code and display question 1 result here.\n",
    "\n",
    "# copy dataframe to use in cleansing\n",
    "cleansing_df = df.copy()\n",
    "\n",
    "# Check user_id is not empty\n",
    "empty_user_id = cleansing_df[(cleansing_df[\"user_id\"].isnull()) | (cleansing_df[\"user_id\"] == '')]\n",
    "if not empty_user_id.empty: print(\"This following data have empty user_id\", empty_user_id)\n",
    "\n",
    "# Identify outliers in ages columns, since there are no instruction for ages to remove or replace\n",
    "# I will create new column that will use to identify user with ages more than 100 for future use such as cleasning or reinput\n",
    "cleansing_df[\"is_valid_age\"] = cleansing_df[\"age\"] > 100\n",
    "\n",
    "# Use fillna function to replace NaN value in age columns with \"-\"\n",
    "cleansing_df[\"age\"].fillna(\"-\", inplace=True)\n",
    "\n",
    "# Remove \",\" in salary column and change data type to float\n",
    "cleansing_df[\"salary\"] = cleansing_df[\"salary\"].apply(lambda x: x.replace(',', '')).astype(float)\n",
    "# Use numpy floor function to remove any decimal and change data type to int\n",
    "import numpy as np\n",
    "cleansing_df[\"salary\"] = np.floor(cleansing_df[\"salary\"]).astype(int)\n",
    "\n",
    "# Use capitalize function to capitalize name columns\n",
    "cleansing_df[\"name\"] = cleansing_df[\"name\"].str.capitalize()\n",
    "\n",
    "# use apply function with pandas to_datetime to check format date \n",
    "# if found error then convert invalid date to Not a Time (NaT) to compare not pd.Nat to return False if found NaT\n",
    "cleansing_df[\"is_valid_date\"] = cleansing_df[\"join_date\"].apply(lambda x: pd.to_datetime(x, format=\"%Y-%m-%d\", errors='coerce') is not pd.NaT)\n",
    "\n",
    "# use is_valid_date column to determine date that is not in right format and not NaN\n",
    "wrong_date_list = cleansing_df[(cleansing_df[\"is_valid_date\"] == False) & (cleansing_df[\"join_date\"].notna())][\"join_date\"]\n",
    "# store index of wrong date format\n",
    "wrong_date_index = cleansing_df[(cleansing_df[\"is_valid_date\"] == False) & (cleansing_df[\"join_date\"].notna())].index\n",
    "\n",
    "# for loop if there are more than one date in wrong format\n",
    "fix_date_list = []\n",
    "for date_value in wrong_date_list:\n",
    "    # Assume that wrong format date is DD/MM/YYYY i.e. 03/12/2023\n",
    "    replace_date = date_value.replace(\"/\",\"\")\n",
    "    # Remove \"/\" then check length if exactly 8 which can easy to slice into day, month, year \n",
    "    if len(replace_date) == 8:\n",
    "        day = replace_date[0:2]\n",
    "        month = replace_date[2:4]\n",
    "        year = replace_date[4:8]\n",
    "    else:       \n",
    "    # find \"/\" then slice number before \"/\" and put in day, month, year in sequence\n",
    "        first_slash = date_value.find(\"/\")\n",
    "        day = date_value[0:first_slash]\n",
    "        date_value_2 = date_value[first_slash+1:]\n",
    "        second_slash = date_value[first_slash+1:].find(\"/\")\n",
    "        month = date_value_2[0:second_slash]\n",
    "        year = date_value_2[second_slash+1:]\n",
    "    \n",
    "    # print error text when list of date as day, month, year is over than usual value which could be value or input format\n",
    "    error_text = \"\"\n",
    "    if(int(day) > 31): error_text += \"day has more than 31 [error value]:\" + day\n",
    "    if(int(month) > 12): error_text += \"\\nmonth has more than 12 [error value]:\" + str(int(month))\n",
    "    if(len(year) > 4): error_text += \"\\nyear has more than 4 digits [error value]:\" + str(year)\n",
    "    if(error_text != \"\"): print(\"Date: \" + date_value + \" unable to convert and contains error below\" + error_text)\n",
    "    \n",
    "    # store list if day, month, year in range and if not store non transform value\n",
    "    if((int(day) <= 31) & (int(month) <= 12) & (len(year) == 4)):\n",
    "        fix_date_list.append(pd.Timestamp(year+\"-\"+str(int(month))+\"-\"+str(int(day))).date())\n",
    "    else :\n",
    "        fix_date_list.append(date_value)\n",
    "# Replace list of fix date format to wrong date format list\n",
    "cleansing_df[\"join_date\"].loc[wrong_date_index] = fix_date_list\n",
    "\n",
    "# After cleansing date then remove NaN value with dropna()\n",
    "cleansing_df = cleansing_df.dropna()\n",
    "\n",
    "# Convert join_date column to datetime format\n",
    "cleansing_df[\"join_date\"] = cleansing_df[\"join_date\"].apply(pd.to_datetime)\n",
    "\n",
    "# Ensure no future date in date column by using datetime today() check with column join_date to store index\n",
    "import datetime\n",
    "future_date_index = cleansing_df[cleansing_df[\"join_date\"] >= pd.Timestamp(datetime.date.today())].index\n",
    "# Drop row with future date, but if row is requried it can be replace with mode() dealing with DataQuality\n",
    "cleansing_df = cleansing_df.drop(future_date_index)\n",
    "\n",
    "# Drop duplicate record with pandas function\n",
    "cleansing_df = cleansing_df.drop_duplicates(subset=['user_id', 'name', 'age'])\n",
    "\n",
    "cleansing_df = cleansing_df.reset_index(drop=True)\n",
    "cleansing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "From question 1, display summary statistics on specific columns (mean, median, max, min, average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id         salary\n",
      "count  19.000000      19.000000\n",
      "mean   12.789474   66210.526316\n",
      "std     7.091301   38552.387082\n",
      "min     1.000000   22000.000000\n",
      "25%     7.500000   49000.000000\n",
      "50%    13.000000   49000.000000\n",
      "75%    18.500000   84500.000000\n",
      "max    24.000000  149000.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.625000</td>\n",
       "      <td>96.312500</td>\n",
       "      <td>62875.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.820313</td>\n",
       "      <td>226.496422</td>\n",
       "      <td>40074.721875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.750000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>45500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>49000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.250000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>60750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>940.000000</td>\n",
       "      <td>149000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id         age         salary\n",
       "count  16.000000   16.000000      16.000000\n",
       "mean   12.625000   96.312500   62875.000000\n",
       "std     6.820313  226.496422   40074.721875\n",
       "min     1.000000   22.000000   22000.000000\n",
       "25%     7.750000   28.000000   45500.000000\n",
       "50%    12.500000   34.000000   49000.000000\n",
       "75%    17.250000   39.000000   60750.000000\n",
       "max    24.000000  940.000000  149000.000000"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write you code and display question 2 result here.\n",
    "\n",
    "# Use describe function on dataframe to display (mean, median, max, min, average)\n",
    "print(cleansing_df.describe())\n",
    "\n",
    "# As age contain \"-\" it cannot use statistics so we need to exclude those record, also age still contain outlier\n",
    "cleansing_df[[\"user_id\", \"age\", \"salary\"]][cleansing_df[\"age\"] != '-'].astype(int).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Display user record who has filled all data (data not be NaN, empty or \"-\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>join_date</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Bob</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Allen</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2023-09-23</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Allen</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2023-09-23</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Chris</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>35000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>Bob</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>Bobb</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>Bab</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>Bob</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>69000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>Toby</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>Eggy</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>Emma</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>22000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21</td>\n",
       "      <td>Mike</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2022-03-15</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>Toby</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24</td>\n",
       "      <td>Gin</td>\n",
       "      <td>940.0</td>\n",
       "      <td>2003-03-02</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id   name    age  join_date  salary\n",
       "0         1   John   28.0 2023-02-01   50000\n",
       "1         3    Bob   34.0 2023-03-02   49000\n",
       "2         6  Allen   26.0 2023-09-23   30000\n",
       "3         7  Allen   26.0 2023-09-23   30000\n",
       "4         8  Chris   28.0 2020-11-13   35000\n",
       "5         9    Bob   33.0 2023-04-02   49000\n",
       "6        10   Bobb   34.0 2023-03-01   49000\n",
       "7        12  Bobby   34.0 2023-03-01   49000\n",
       "8        13    Bab   39.0 2023-02-02   49000\n",
       "9        15    Bob   39.0 2024-03-02   69000\n",
       "10       16   Toby   34.0 2023-03-02   49000\n",
       "11       17   Eggy   36.0 2023-12-16   58000\n",
       "12       18   Emma   22.0 2023-03-02   22000\n",
       "13       21   Mike   54.0 2022-03-15  120000\n",
       "14       22   Toby  134.0 2023-03-02  149000\n",
       "15       24    Gin  940.0 2003-03-02  149000"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write you code and display question 3 result here.\n",
    "\n",
    "# If using cleansing dataframe from Question 1 then \n",
    "# Drop rows with NaN and Checks each row for \"-\" and keeps only rows that don't contain \"-\"\n",
    "filtered_df = cleansing_df.dropna() \n",
    "filtered_df = filtered_df[filtered_df.ne('-').all(axis=1)] \n",
    "filtered_df[[\"user_id\", \"name\", \"age\", \"join_date\", \"salary\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>join_date</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Bob</td>\n",
       "      <td>34.0</td>\n",
       "      <td>02/03/2023</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bob</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>allen</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2023-09-23</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Allen</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2023-09-23</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>chris</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>35,000.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>Bob</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>Bobb</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Bob</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>Bab</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>Bob</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>Bob</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>69000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>Toby</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>Eggy</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>Bab</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>Emma</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>22,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Eggy</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>Bob</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>MIke</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2022-03-15</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>Toby</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2023-03-02</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>Vin</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2223-03-02</td>\n",
       "      <td>148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>Gin</td>\n",
       "      <td>940.0</td>\n",
       "      <td>2003-03-02</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>james</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2043-03-02</td>\n",
       "      <td>169000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id   name    age   join_date     salary\n",
       "0         1   John   28.0  2023-02-01      50000\n",
       "1         3    Bob   34.0  02/03/2023      49000\n",
       "2         3    Bob   34.0  2023-03-02      49000\n",
       "3         6  allen   26.0  2023-09-23      30000\n",
       "4         7  Allen   26.0  2023-09-23      30000\n",
       "5         8  chris   28.0  2020-11-13  35,000.25\n",
       "6         9    Bob   33.0  2023-04-02      49000\n",
       "7        10   Bobb   34.0  2023-03-01      49000\n",
       "8         9    Bob   33.0  2023-04-02      49000\n",
       "9        12  Bobby   34.0  2023-03-01      49000\n",
       "10       13    Bab   39.0  2023-02-02      49000\n",
       "11        3    Bob   34.0  2023-03-02      49000\n",
       "12       15    Bob   39.0  2024-03-02      69000\n",
       "13       16   Toby   34.0  2023-03-02      49000\n",
       "14       17   Eggy   36.0  2023-12-16      58000\n",
       "15       13    Bab   39.0  2023-02-02      49000\n",
       "16       18   Emma   22.0  2023-03-02     22,000\n",
       "17       17   Eggy   36.0  2023-12-16      58000\n",
       "18        9    Bob   33.0  2023-04-02      49000\n",
       "19       21   MIke   54.0  2022-03-15     120000\n",
       "20       22   Toby  134.0  2023-03-02     149000\n",
       "21       23    Vin   40.0  2223-03-02     148000\n",
       "22       24    Gin  940.0  2003-03-02     149000\n",
       "23       25  james   60.0  2043-03-02     169000"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If using non cleansing dataframe then\n",
    "# Drop rows with NaN and Checks each row for \"-\" and keeps only rows that don't contain \"-\"\n",
    "filtered_ori_df = df.dropna()  # Drop rows with NaN\n",
    "filtered_ori_df = filtered_ori_df[filtered_ori_df.ne('-').all(axis=1)] \n",
    "filtered_ori_df.reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
